{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#!pip install open_clip_torch\n",
    "import open_clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "# Load the model and preprocessing function\n",
    "##### Load Model #####\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', device=device, pretrained='datacomp_xl_s13b_b90k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [\"input/000805.jpg\",\"input/000817.jpg\", \"input/000830.jpg\",\"input/000843.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = {\n",
    "    \"refueling\":  [\"input/000805.jpg\",\"input/000817.jpg\", \"input/000830.jpg\",\"input/000843.jpg\"],\n",
    "    \"standings\": [\"input/000844.jpg\",\"input/000861.jpg\", \"input/000879.jpg\",\"input/000897.jpg\"],\n",
    "    \"monk\":[\"input/000898.jpg\",\"input/000910.jpg\", \"input/000922.jpg\",\"input/000935.jpg\"],\n",
    "    \"statues\":[\"input/000936.jpg\",\"input/000947.jpg\", \"input/000958.jpg\",\"input/000969.jpg\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scene_vectors(scenes):\n",
    "    scene_vectors = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for scene, image_paths in scenes.items():\n",
    "            vectors = []\n",
    "            for image_path in image_paths:\n",
    "                # Load and preprocess the image\n",
    "                image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "                # Calculate the vector\n",
    "                vector = model.encode_image(image).cpu().numpy()\n",
    "                vectors.append(vector)\n",
    "            # Average the vectors to get a single vector for the scene\n",
    "            avg_scene_vector = sum(vectors) / len(vectors)\n",
    "            scene_vectors[scene] = vectors\n",
    "            scene_vectors[scene].append(avg_scene_vector)\n",
    "    \n",
    "    return scene_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_vectors = calculate_scene_vectors(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_vectors[\"refueling\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_the_scene(text, scene_vectors):\n",
    "    # Tokenize the text\n",
    "    text_inputs = open_clip.tokenize([text]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Calculate the text vector\n",
    "        text_vector = model.encode_text(text_inputs).cpu().numpy()\n",
    "        \n",
    "        # Calculate the similarity between text vector and each scene vector\n",
    "        similarities = {}\n",
    "        for scene, scene_vector in scene_vectors.items():\n",
    "            # Use cosine similarity\n",
    "            ts_scene_vt = torch.tensor(np.array(scene_vector)).squeeze(1)\n",
    "            ts_text_vt = torch.tensor(text_vector)\n",
    "            similarity = torch.nn.functional.cosine_similarity(ts_text_vt.expand(ts_scene_vt.shape[0],-1), ts_scene_vt, dim=1)\n",
    "            similarities[scene] = similarity.max().item()\n",
    "    \n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many monks stands next to each other: {'refueling': 0.05392731726169586, 'standings': 0.17613336443901062, 'monk': 0.16794085502624512, 'statues': 0.15584662556648254}\n"
     ]
    }
   ],
   "source": [
    "text = \"many monks stands next to each other\"\n",
    "scene_confidences = predict_the_scene(text, scene_vectors)\n",
    "print(f\"{text}: {scene_confidences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "many guys with yellow clothes: {'refueling': 0.10196693241596222, 'standings': 0.16138969361782074, 'monk': 0.09902562201023102, 'statues': 0.1291029453277588}\n"
     ]
    }
   ],
   "source": [
    "text = \"many guys with yellow clothes\"\n",
    "scene_confidences = predict_the_scene(text, scene_vectors)\n",
    "print(f\"{text}: {scene_confidences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man with his car being refueled: {'refueling': 0.19195976853370667, 'standings': -0.012485004030168056, 'monk': -0.004050338640809059, 'statues': -0.04690425097942352}\n"
     ]
    }
   ],
   "source": [
    "text = \"a man with his car being refueled\"\n",
    "scene_confidences = predict_the_scene(text, scene_vectors)\n",
    "print(f\"{text}: {scene_confidences}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a man with white suit standing next to 2 women with puper and blue clothes: {'refueling': 0.09279666095972061, 'standings': 0.20089998841285706, 'monk': 0.11528919637203217, 'statues': 0.07210902869701385}\n"
     ]
    }
   ],
   "source": [
    "text = \"a man with white suit standing next to 2 women with puper and blue clothes\"\n",
    "scene_confidences = predict_the_scene(text, scene_vectors)\n",
    "print(f\"{text}: {scene_confidences}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
