{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1T5lc2fDz2H6UWZ0H97D66rfHLuJsIXkH","authorship_tag":"ABX9TyOsOurQ46waaHjm8qJ3CTsB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":38,"metadata":{"id":"EAq-JGlkSNx1","executionInfo":{"status":"ok","timestamp":1721285080418,"user_tz":-420,"elapsed":554,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"outputs":[],"source":["### Set values here ###\n","config = 'configs/zero_shot/train/k400/16_16_vifi_clip.yaml'\n","output_folder_name = \"exp\"\n","pretrained_model_path = \"/content/drive/MyDrive/Colabs/CLIP/vifi_clip_10_epochs_k400_full_finetuned.pth\"\n","# List the action names for which ViFi-CLIP will perform action recognition\n","class_names = ['dancing', 'drum beating', 'swimming', \"climbing stairs\"]\n","# Load your video example:\n","video_path = '/content/drive/MyDrive/Colabs/CLIP/AMADEUS_eat_u_nm_np1_fr_goo_10.avi'"]},{"cell_type":"code","source":["# !git clone https://github.com/muzairkhattak/ViFi-CLIP.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xSMf4FieTX7Z","executionInfo":{"status":"ok","timestamp":1721280339932,"user_tz":-420,"elapsed":2682,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"f326ef16-1e59-499a-c6fa-6386b5763e50"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ViFi-CLIP'...\n","remote: Enumerating objects: 265, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (30/30), done.\u001b[K\n","remote: Total 265 (delta 16), reused 14 (delta 6), pack-reused 227\u001b[K\n","Receiving objects: 100% (265/265), 23.77 MiB | 24.68 MiB/s, done.\n","Resolving deltas: 100% (101/101), done.\n"]}]},{"cell_type":"code","source":["#!pip install -r requirements.txt\n","# !pip3 install openmim # if mmcv cannot be installed\n","# !mim install mmcv-full"],"metadata":{"id":"epg9K3VrdXwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd ViFi-CLIP"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NcsH-jxTpKE","executionInfo":{"status":"ok","timestamp":1721282742544,"user_tz":-420,"elapsed":525,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"1043afa1-3cd0-45d4-ae42-01d79777ac79"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/ViFi-CLIP\n"]}]},{"cell_type":"code","source":["%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRhJFK4dTyha","executionInfo":{"status":"ok","timestamp":1721282745183,"user_tz":-420,"elapsed":11,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"2a1bd1e0-c6db-4239-c81b-d5656994b622"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mclip\u001b[0m/      \u001b[01;34mdatasets_splits\u001b[0m/  LICENSE    requirements.txt  ViFi-CLIP_Inference_custom_video.ipynb\n","\u001b[01;34mconfigs\u001b[0m/   \u001b[01;34mdocs\u001b[0m/             main.py    \u001b[01;34mtrainers\u001b[0m/\n","\u001b[01;34mdatasets\u001b[0m/  \u001b[01;34mlabels\u001b[0m/           README.md  \u001b[01;34mutils\u001b[0m/\n"]}]},{"cell_type":"code","source":["# !pip install -r requirements.txt"],"metadata":{"id":"bCYc26LaT7Z1","executionInfo":{"status":"ok","timestamp":1721282088395,"user_tz":-420,"elapsed":670,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from utils.config import get_config\n","from utils.logger import create_logger\n","import time\n","import numpy as np\n","from utils.config import get_config\n","from trainers import vificlip\n","from datasets.pipeline import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2qxkPfNJSuUD","executionInfo":{"status":"ok","timestamp":1721282751619,"user_tz":-420,"elapsed":4113,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"3d06db0d-9124-4b34-8770-72ae9bcf1eab"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# Step 1:\n","# Configuration class\n","class parse_option():\n","    def __init__(self):\n","        self.config = config\n","        self.output =  output_folder_name   # Name of output folder to store logs and save weights\n","        self.resume = pretrained_model_path\n","        # No need to change below args.\n","        self.only_test = True\n","        self.opts = None\n","        self.batch_size = None\n","        self.pretrained = None\n","        self.accumulation_steps = None\n","        self.local_rank = 0\n","args = parse_option()\n","config = get_config(args)\n","# logger"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qf-S4oUGbbRf","executionInfo":{"status":"ok","timestamp":1721285084899,"user_tz":-420,"elapsed":683,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"546d9c94-bfcf-4e26-8b16-319981f657e7"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["=> merge config from configs/zero_shot/train/k400/16_16_vifi_clip.yaml\n"]}]},{"cell_type":"code","source":["!mkdir exp"],"metadata":{"id":"fp-6pgfHdDw7","executionInfo":{"status":"ok","timestamp":1721282876320,"user_tz":-420,"elapsed":8,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["logger = create_logger(output_dir=args.output, name=f\"{config.MODEL.ARCH}\")\n","print(2)\n","logger.info(f\"working dir: {config.OUTPUT}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTpwXY3UbcBH","executionInfo":{"status":"ok","timestamp":1721285087400,"user_tz":-420,"elapsed":577,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"07b73ca1-d76e-4ed0-da21-d9ea4a929c2d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","[2024-07-18 06:44:46 ViT-B/16](<ipython-input-40-c63b87ca9809> 3): INFO working dir: exp\n","[2024-07-18 06:44:46 ViT-B/16](<ipython-input-40-c63b87ca9809> 3): INFO working dir: exp\n","[2024-07-18 06:44:46 ViT-B/16](<ipython-input-40-c63b87ca9809> 3): INFO working dir: exp\n"]}]},{"cell_type":"code","source":["# Step 2:\n","# Create the ViFi-CLIP models and load pretrained weights\n","model = vificlip.returnCLIP(config,\n","                            logger=logger,\n","                            class_names=class_names,)\n","model = model.float().cuda()  # changing to cuda here"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWO2_VondRzf","executionInfo":{"status":"ok","timestamp":1721285094073,"user_tz":-420,"elapsed":5030,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"7fe16b40-d816-451a-8cc5-d5b2eefa0555"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-07-18 06:44:48 ViT-B/16](vificlip.py 202): INFO Loading CLIP (backbone: ViT-B/16)\n","[2024-07-18 06:44:48 ViT-B/16](vificlip.py 202): INFO Loading CLIP (backbone: ViT-B/16)\n","[2024-07-18 06:44:48 ViT-B/16](vificlip.py 202): INFO Loading CLIP (backbone: ViT-B/16)\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 205): INFO Building ViFi-CLIP CLIP\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 205): INFO Building ViFi-CLIP CLIP\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 205): INFO Building ViFi-CLIP CLIP\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 222): INFO Turning on gradients for COMPLETE ViFi-CLIP model\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 222): INFO Turning on gradients for COMPLETE ViFi-CLIP model\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 222): INFO Turning on gradients for COMPLETE ViFi-CLIP model\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 245): INFO Parameters to be updated: {'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.conv1.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.class_embedding', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.proj', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.ln_pre.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.positional_embedding', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'logit_scale', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias'}\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 245): INFO Parameters to be updated: {'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.conv1.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.class_embedding', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.proj', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.ln_pre.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.positional_embedding', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'logit_scale', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias'}\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 245): INFO Parameters to be updated: {'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.conv1.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.class_embedding', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.proj', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.ln_pre.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.positional_embedding', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'logit_scale', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias'}\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 246): INFO Total learnable items: 301\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 246): INFO Total learnable items: 301\n","[2024-07-18 06:44:53 ViT-B/16](vificlip.py 246): INFO Total learnable items: 301\n"]}]},{"cell_type":"code","source":["logger.info(f\"==============> Resuming form {config.MODEL.RESUME}....................\")\n","print(config.MODEL.RESUME)\n","checkpoint = torch.load(config.MODEL.RESUME, map_location='cpu')\n","load_state_dict = checkpoint['model']\n","# now remove the unwanted keys:\n","if \"module.prompt_learner.token_prefix\" in load_state_dict:\n","    del load_state_dict[\"module.prompt_learner.token_prefix\"]\n","\n","if \"module.prompt_learner.token_suffix\" in load_state_dict:\n","    del load_state_dict[\"module.prompt_learner.token_suffix\"]\n","\n","if \"module.prompt_learner.complete_text_embeddings\" in load_state_dict:\n","    del load_state_dict[\"module.prompt_learner.complete_text_embeddings\"]\n","# create new OrderedDict that does not contain `module.`\n","from collections import OrderedDict\n","new_state_dict = OrderedDict()\n","for k, v in load_state_dict.items():\n","    name = k[7:] # remove `module.`\n","    new_state_dict[name] = v"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAjvoQmKdler","executionInfo":{"status":"ok","timestamp":1721284585012,"user_tz":-420,"elapsed":37157,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"27a45480-f9e5-4f20-95b9-fba23a9ccc81"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-07-18 06:35:47 ViT-B/16](<ipython-input-31-8d5d4db1129f> 1): INFO ==============> Resuming form /content/drive/MyDrive/Colabs/CLIP/vifi_clip_10_epochs_k400_full_finetuned.pth....................\n","[2024-07-18 06:35:47 ViT-B/16](<ipython-input-31-8d5d4db1129f> 1): INFO ==============> Resuming form /content/drive/MyDrive/Colabs/CLIP/vifi_clip_10_epochs_k400_full_finetuned.pth....................\n","[2024-07-18 06:35:47 ViT-B/16](<ipython-input-31-8d5d4db1129f> 1): INFO ==============> Resuming form /content/drive/MyDrive/Colabs/CLIP/vifi_clip_10_epochs_k400_full_finetuned.pth....................\n","/content/drive/MyDrive/Colabs/CLIP/vifi_clip_10_epochs_k400_full_finetuned.pth\n"]}]},{"cell_type":"code","source":["# load params\n","msg = model.load_state_dict(new_state_dict, strict=False)\n","logger.info(f\"resume model: {msg}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SrO7TmRLkhlR","executionInfo":{"status":"ok","timestamp":1721285097828,"user_tz":-420,"elapsed":840,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"1a7d8fa6-2bd7-41c6-fc6c-4bdcef4542c3"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-07-18 06:44:56 ViT-B/16](<ipython-input-42-09d8243ad764> 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])\n","[2024-07-18 06:44:56 ViT-B/16](<ipython-input-42-09d8243ad764> 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])\n","[2024-07-18 06:44:56 ViT-B/16](<ipython-input-42-09d8243ad764> 3): INFO resume model: _IncompatibleKeys(missing_keys=['prompt_learner.complete_text_embeddings'], unexpected_keys=[])\n"]}]},{"cell_type":"code","source":["# Step 3:\n","# Preprocessing for video\n","img_norm_cfg = dict(\n","    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n","scale_resize = int(256 / 224 * config.DATA.INPUT_SIZE)\n","val_pipeline = [\n","    dict(type='DecordInit'),\n","    dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=config.DATA.NUM_FRAMES, test_mode=True),\n","    dict(type='DecordDecode'),\n","    dict(type='Resize', scale=(-1, scale_resize)),\n","    dict(type='CenterCrop', crop_size=config.DATA.INPUT_SIZE),\n","    dict(type='Normalize', **img_norm_cfg),\n","    dict(type='FormatShape', input_format='NCHW'),\n","    dict(type='Collect', keys=['imgs'], meta_keys=[]),\n","    dict(type='ToTensor', keys=['imgs'])\n","]\n","if config.TEST.NUM_CROP == 3:\n","    val_pipeline[3] = dict(type='Resize', scale=(-1, config.DATA.INPUT_SIZE))\n","    val_pipeline[4] = dict(type='ThreeCrop', crop_size=config.DATA.INPUT_SIZE)\n","if config.TEST.NUM_CLIP > 1:\n","    val_pipeline[1] = dict(type='SampleFrames', clip_len=1, frame_interval=1, num_clips=config.DATA.NUM_FRAMES, multiview=config.TEST.NUM_CLIP)\n","pipeline = Compose(val_pipeline)"],"metadata":{"id":"Gizh70ucfA6P","executionInfo":{"status":"ok","timestamp":1721285676795,"user_tz":-420,"elapsed":667,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["dict_file = {'filename': video_path, 'tar': False, 'modality': 'RGB', 'start_index': 0}"],"metadata":{"id":"enmS3vgmkZul","executionInfo":{"status":"ok","timestamp":1721285680225,"user_tz":-420,"elapsed":692,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["# !pip install decord"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgZT36ftkvK_","executionInfo":{"status":"ok","timestamp":1721284893872,"user_tz":-420,"elapsed":7349,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"ada617f4-22a1-4196-d285-57a48ed90277"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting decord\n","  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord) (1.25.2)\n","Installing collected packages: decord\n","Successfully installed decord-0.6.0\n"]}]},{"cell_type":"code","source":["np.int = np.int64"],"metadata":{"id":"yVaeqH7MoAEt","executionInfo":{"status":"ok","timestamp":1721285741774,"user_tz":-420,"elapsed":963,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["video = pipeline(dict_file)\n","video_tensor = video['imgs'].unsqueeze(0).cuda().float()\n","# Inference through ViFi-CLIP\n","with torch.no_grad():\n","    with torch.cuda.amp.autocast():\n","        logits = model(video_tensor)\n","pred_index = logits.argmax(-1)"],"metadata":{"id":"HvgI6GJ3kog1","executionInfo":{"status":"ok","timestamp":1721285746454,"user_tz":-420,"elapsed":3011,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["print(f'logits: {logits}')\n","print(f'predicted action category is : {class_names[pred_index]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cxdZ9cWkl4YC","executionInfo":{"status":"ok","timestamp":1721285786738,"user_tz":-420,"elapsed":491,"user":{"displayName":"Đài Phan Trọng","userId":"05822439245286031923"}},"outputId":"4672f8e7-d691-41ba-a7a2-fe6e2841feed"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["logits: tensor([[10.5938,  9.2500,  8.1172, 10.5000]], device='cuda:0',\n","       dtype=torch.float16)\n","predicted action category is : dancing\n"]}]}]}